# VA KnowVA Manual Scraper

This project contains a Python script (`scrape_va_manual.py`) designed to scrape content from the VA KnowVA manual pages. It can recursively traverse linked pages, convert article content to Markdown, and aggregate all extracted Markdown into a single output file.

## Features

*   **Recursive Scraping**: Traverses linked pages within the KnowVA manual website down to a specified depth.
*   **JavaScript Rendering**: Utilizes `requests-html` to render JavaScript on the initial page, allowing access to dynamically loaded content.
*   **Article vs. Directory Distinction**: Heuristically determines if a page is an article or a directory/listing page to process it accordingly.
*   **HTML to Markdown Conversion**: Converts the main content of article pages from HTML to Markdown format using `markdownify`.
*   **Content Aggregation**: Combines the Markdown content from all scraped articles into a single output file.
*   **Mocking for Deep Traversal**: For pages beyond the initial one (depth > 0), the script uses mock HTML. This is a workaround for performance issues and potential WAF (Web Application Firewall) blocking encountered when fetching many pages live from the target website, primarily aiding in testing the script's traversal and aggregation logic.

## Main Dependencies

The script relies on the following main Python libraries:

*   `requests-html`: For fetching HTML and rendering JavaScript (for the initial page).
*   `beautifulsoup4`: For parsing HTML and extracting specific content.
*   `markdownify`: For converting HTML content to Markdown.
*   `urllib.parse`: For URL joining and parsing (part of the Python standard library).

## Basic Usage

To use the script, run it from the command line, providing the starting URL, and optionally specifying the maximum recursion depth and an output file name.

**Example:**

```bash
python scrape_va_manual.py "https://www.knowva.ebenefits.va.gov/system/templates/selfservice/va_ssnew/help/customer/locale/en-US/portal/554400000001018/topic/554400000004049/M21-1-Adjudication-Procedures-Manual" --max-depth 2 -o m21_1_manual.md
```

This command will:
*   Start scraping from the provided URL.
*   Recursively fetch and process pages up to a depth of 2 levels from the starting page.
*   Save the aggregated Markdown content to `m21_1_manual.md`.

For a full list of options and their descriptions, you can use the script's help flag:
```bash
python scrape_va_manual.py --help
```

## Known Issues

*   **Browser Session Closure**: Closing the Pyppeteer browser instance (used by `requests-html` for JavaScript rendering) via `session.browser.close()` can sometimes cause indefinite hangs or timeouts in certain sandboxed execution environments. This call is currently commented out in the `scrape_va_manual.py` script's `finally` block to ensure script completion. This might lead to lingering browser processes if the script is run repeatedly and these processes are not managed externally. The underlying `requests` session (`session.close()`) is still properly closed.

## Existing Content

The repository may contain Markdown files such as `Part1.md` and `VA_Part1_test.md`. These files are typically:
*   Example outputs generated by the `scrape_va_manual.py` script.
*   Test data used during the development or testing of the scraper.

They can serve as a reference for the expected output format or for specific scraped content sections.
